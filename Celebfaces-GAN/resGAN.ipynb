{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torch_snippets import *\n",
    "from torchsummary import summary\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class resDiscriminator(nn.Module):\n",
    "    def __init__(self,reduction=5,repeat=0,reduction_p2=1,divisor=4,n_map=64,img_size=128,\n",
    "                 relu=0.2,n_features=32,feature_dim=8,minibatch_input_dim=512,dropout=0.1):\n",
    "        super().__init__()\n",
    "        max_reduction = int(math.log2(img_size))\n",
    "        #print(f\"max reduction {max_reduction}\")\n",
    "        self.reduction = min(reduction,max_reduction)\n",
    "        self.reduction_p2 = max(min(reduction_p2,max_reduction-reduction),0)\n",
    "        #print(f\"reduction 1: {self.reduction}\")\n",
    "        #print(f\"reduction 2: {self.reduction_p2}\")\n",
    "        self.final_map_size = img_size // 2**(self.reduction+self.reduction_p2)\n",
    "        #print(f\"final map size: {self.final_map_size}\")\n",
    "        self.final_n_map = n_map * 2**(self.reduction+1)\n",
    "        #print(f\"final n map is: {self.final_n_map}\")\n",
    "        self.minibatch_input_dim = minibatch_input_dim\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        self.n_features = n_features\n",
    "        self.feature_dim = feature_dim\n",
    "        self.relu = relu\n",
    "        self.repeat = repeat\n",
    "        self.divisor = divisor\n",
    "        self.activation = nn.LeakyReLU(self.relu)\n",
    "        self.minibatch_linear = nn.Linear(minibatch_input_dim,n_features*feature_dim)\n",
    "        self.final_dense = nn.Linear(self.minibatch_input_dim+n_features*2,1)\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(3,n_map,7,1,3,bias=False), # =\n",
    "            nn.BatchNorm2d(n_map),\n",
    "            nn.LeakyReLU(self.relu),\n",
    "            nn.Conv2d(n_map,n_map*2,8,2,3,bias=False), # /2\n",
    "            nn.BatchNorm2d(n_map*2),\n",
    "            nn.LeakyReLU(self.relu)\n",
    "        )\n",
    "        self.initial_block_conv = nn.Sequential(\n",
    "            nn.Conv2d(n_map*2,n_map*4,1,1,0,bias=False), # =\n",
    "            nn.BatchNorm2d(n_map*4)\n",
    "        )\n",
    "        self.initial_block_bn = nn.Sequential(\n",
    "            nn.Conv2d(n_map*2,n_map,1,1,0,bias=False), # =\n",
    "            nn.BatchNorm2d(n_map),\n",
    "            nn.LeakyReLU(self.relu),\n",
    "            nn.Conv2d(n_map,n_map,3,1,1), # =\n",
    "            nn.BatchNorm2d(n_map),\n",
    "            nn.LeakyReLU(self.relu),\n",
    "            nn.Conv2d(n_map,n_map*4,1,1,0,bias=False), # =\n",
    "            nn.BatchNorm2d(n_map*4)\n",
    "        )\n",
    "        n = n_map * 4\n",
    "        self.conv_blocks = nn.ModuleList(\n",
    "            [self._normal_block(n*2**i,n*2**(i+1)) for i in range(self.reduction-1)]\n",
    "        )\n",
    "        self.bn_shrink_blocks = nn.ModuleList(\n",
    "            [self._bottleneck_block(n*2**i,n*2**(i+1),True) for i in range(self.reduction-1)]\n",
    "        )\n",
    "        self.bn_repeat_blocks = nn.ModuleList(\n",
    "            [self._bottleneck_block(n*2**(i+1),n*2**(i+1),False) for i in range(self.reduction-1) for _ in range(repeat)]\n",
    "        )\n",
    "        #print(self.final_n_map)\n",
    "        self.final_conv = nn.ModuleList(\n",
    "            [self._normal_block(self.final_n_map,self.final_n_map) for _ in range(self.reduction_p2)] + \\\n",
    "                [nn.Conv2d(self.final_n_map,minibatch_input_dim,self.final_map_size,1,0)]\n",
    "        )\n",
    "\n",
    "    \n",
    "    def _normal_block(self,in_c,out_c):\n",
    "        return nn.Sequential(nn.Conv2d(in_c,out_c,1,2,0,bias=False),nn.BatchNorm2d(out_c)) # /2\n",
    "    \n",
    "    def _bottleneck_block(self,in_c,out_c,shrink=True):\n",
    "        # if shrink, output = (64 - 2)/2 + 1 = 32\n",
    "        # if not shrink, output = (64 - 1) / 1 + 1 = 64\n",
    "        final_config = 2 if shrink else 1\n",
    "        middle_c = out_c // self.divisor\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_c,middle_c,1,1,0,bias=False), # =\n",
    "            nn.BatchNorm2d(middle_c),\n",
    "            nn.LeakyReLU(self.relu),\n",
    "            nn.Conv2d(middle_c,middle_c,3,1,1), # = \n",
    "            nn.BatchNorm2d(middle_c),\n",
    "            nn.LeakyReLU(self.relu),\n",
    "            nn.Conv2d(middle_c,out_c,final_config,final_config,0,bias=False), # /2 or =\n",
    "            nn.BatchNorm2d(out_c)    \n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def _minibatch_discrimination(self,x):\n",
    "        n_feature,feature_dim = self.n_features, self.feature_dim\n",
    "        batch_size = x.shape[0]\n",
    "        x_copy = x.clone()\n",
    "        x = self.minibatch_linear(x) # e.g., (4, 6)\n",
    "        #print(f\"after linear layer x shape: {x.shape}\")\n",
    "        x = x.view(-1,n_feature,feature_dim) # e.g., (4,3,2)\n",
    "        #print(f\"after reshape x shape: {x.shape}\")\n",
    "        # create mask\n",
    "        mask = torch.eye(batch_size) # (4,4)\n",
    "        mask = mask.unsqueeze(1) # (4, 1, 4)\n",
    "        mask = (1 - mask).to('cuda')\n",
    "        # calculate diff between features: goal (4, 3, 4)\n",
    "        m1 = x.unsqueeze(3) # (4,3 2, 1)\n",
    "        m2 = x.transpose(0,2).transpose(0,1).unsqueeze(0) # (1, 3, 2, 4)\n",
    "        diff = torch.abs(m1 - m2) # (4, 3, 2, 4)\n",
    "        diff = torch.sum(diff, dim=2) # (4, 3, 4)\n",
    "        diff = torch.exp(-diff)\n",
    "        diff_masked = diff * mask\n",
    "        #print(f\"diff_masked shape {diff_masked.shape}\")\n",
    "        # split sum up the differences goal (4,3*2)\n",
    "        def half(tensor,second):\n",
    "            return tensor[:,:,second*batch_size//2:(second+1)*batch_size//2]\n",
    "        first_half = half(diff_masked, 0) # (4, 3, 2)\n",
    "        first_half = torch.sum(first_half, dim=2) / torch.sum(first_half) # (4, 3)\n",
    "        second_half = half(diff_masked, 1) \n",
    "        second_half = torch.sum(second_half, dim=2) / torch.sum(second_half)\n",
    "        features = torch.cat([first_half,second_half], dim=1) # (4, 3*2)\n",
    "        #print(f\"features shape {features.shape}\")\n",
    "        # merge back to the input, goal (4,3*2*2)\n",
    "        output = torch.cat([x_copy,features], dim=1)\n",
    "        #print(output.shape)\n",
    "        return output\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(self.initial_conv(x))\n",
    "        x1 = self.initial_block_conv(x)\n",
    "        x2 = self.initial_block_bn(x)\n",
    "        x = self.dropout(self.activation(x1 + x2))\n",
    "        for i in range(self.reduction-1):\n",
    "            x1 = self.conv_blocks[i](x)\n",
    "            #print(x1.shape)\n",
    "            x2 = self.bn_shrink_blocks[i](x)\n",
    "            #print(f\"shrinking block: x1 shape {x1.shape}, x2 shape {x2.shape}\")\n",
    "            for j in range(self.repeat):\n",
    "                idx = j + self.repeat * i\n",
    "                x2 = self.bn_repeat_blocks[idx](x2)\n",
    "                #print(f\"repeating block: x2 shape {x2.shape}\")\n",
    "            x = self.dropout(self.activation(x1+x2))\n",
    "        #print(f\"begin {x.shape}\")\n",
    "        for i in range(self.reduction_p2+1):\n",
    "            if i < self.reduction_p2:\n",
    "                x = self.dropout(self.activation(self.final_conv[i](x)))\n",
    "                #print(x.shape)\n",
    "            else:\n",
    "                x = self.dropout(self.final_conv[i](x))\n",
    "                #print(f\"last {x.shape}\")\n",
    "        x = nn.Flatten(start_dim=1)(x)\n",
    "        #print(f\"flatten size: {x.shape}\")\n",
    "        x = self._minibatch_discrimination(x)\n",
    "        #print(f\"after minibatch discrimination: {x.shape}\")\n",
    "        x = self.final_dense(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 64, 64]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 128, 128]        4,704\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 32, 128, 128]        64\n",
      "|    └─LeakyReLU: 2-3                    [-1, 32, 128, 128]        --\n",
      "|    └─Conv2d: 2-4                       [-1, 64, 64, 64]          131,072\n",
      "|    └─BatchNorm2d: 2-5                  [-1, 64, 64, 64]          128\n",
      "|    └─LeakyReLU: 2-6                    [-1, 64, 64, 64]          --\n",
      "├─Dropout2d: 1-2                         [-1, 64, 64, 64]          --\n",
      "├─Sequential: 1-3                        [-1, 128, 64, 64]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 128, 64, 64]         8,192\n",
      "|    └─BatchNorm2d: 2-8                  [-1, 128, 64, 64]         256\n",
      "├─Sequential: 1-4                        [-1, 128, 64, 64]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 32, 64, 64]          2,048\n",
      "|    └─BatchNorm2d: 2-10                 [-1, 32, 64, 64]          64\n",
      "|    └─LeakyReLU: 2-11                   [-1, 32, 64, 64]          --\n",
      "|    └─Conv2d: 2-12                      [-1, 32, 64, 64]          9,248\n",
      "|    └─BatchNorm2d: 2-13                 [-1, 32, 64, 64]          64\n",
      "|    └─LeakyReLU: 2-14                   [-1, 32, 64, 64]          --\n",
      "|    └─Conv2d: 2-15                      [-1, 128, 64, 64]         4,096\n",
      "|    └─BatchNorm2d: 2-16                 [-1, 128, 64, 64]         256\n",
      "├─LeakyReLU: 1-5                         [-1, 128, 64, 64]         --\n",
      "├─Dropout2d: 1-6                         [-1, 128, 64, 64]         --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Sequential: 2-17                  [-1, 256, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 256, 32, 32]         32,768\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 256, 32, 32]         512\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Sequential: 2-18                  [-1, 256, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-3                  [-1, 64, 64, 64]          8,192\n",
      "|    |    └─BatchNorm2d: 3-4             [-1, 64, 64, 64]          128\n",
      "|    |    └─LeakyReLU: 3-5               [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-6                  [-1, 64, 64, 64]          36,928\n",
      "|    |    └─BatchNorm2d: 3-7             [-1, 64, 64, 64]          128\n",
      "|    |    └─LeakyReLU: 3-8               [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 256, 32, 32]         65,536\n",
      "|    |    └─BatchNorm2d: 3-10            [-1, 256, 32, 32]         512\n",
      "├─LeakyReLU: 1-7                         [-1, 256, 32, 32]         --\n",
      "├─Dropout2d: 1-8                         [-1, 256, 32, 32]         --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Sequential: 2-19                  [-1, 512, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-11                 [-1, 512, 16, 16]         131,072\n",
      "|    |    └─BatchNorm2d: 3-12            [-1, 512, 16, 16]         1,024\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Sequential: 2-20                  [-1, 512, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 128, 32, 32]         32,768\n",
      "|    |    └─BatchNorm2d: 3-14            [-1, 128, 32, 32]         256\n",
      "|    |    └─LeakyReLU: 3-15              [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-16                 [-1, 128, 32, 32]         147,584\n",
      "|    |    └─BatchNorm2d: 3-17            [-1, 128, 32, 32]         256\n",
      "|    |    └─LeakyReLU: 3-18              [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-19                 [-1, 512, 16, 16]         262,144\n",
      "|    |    └─BatchNorm2d: 3-20            [-1, 512, 16, 16]         1,024\n",
      "├─LeakyReLU: 1-9                         [-1, 512, 16, 16]         --\n",
      "├─Dropout2d: 1-10                        [-1, 512, 16, 16]         --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Sequential: 2-21                  [-1, 1024, 8, 8]          --\n",
      "|    |    └─Conv2d: 3-21                 [-1, 1024, 8, 8]          524,288\n",
      "|    |    └─BatchNorm2d: 3-22            [-1, 1024, 8, 8]          2,048\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Sequential: 2-22                  [-1, 1024, 8, 8]          --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 256, 16, 16]         131,072\n",
      "|    |    └─BatchNorm2d: 3-24            [-1, 256, 16, 16]         512\n",
      "|    |    └─LeakyReLU: 3-25              [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-26                 [-1, 256, 16, 16]         590,080\n",
      "|    |    └─BatchNorm2d: 3-27            [-1, 256, 16, 16]         512\n",
      "|    |    └─LeakyReLU: 3-28              [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 1024, 8, 8]          1,048,576\n",
      "|    |    └─BatchNorm2d: 3-30            [-1, 1024, 8, 8]          2,048\n",
      "├─LeakyReLU: 1-11                        [-1, 1024, 8, 8]          --\n",
      "├─Dropout2d: 1-12                        [-1, 1024, 8, 8]          --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Sequential: 2-23                  [-1, 1024, 4, 4]          --\n",
      "|    |    └─Conv2d: 3-31                 [-1, 1024, 4, 4]          1,048,576\n",
      "|    |    └─BatchNorm2d: 3-32            [-1, 1024, 4, 4]          2,048\n",
      "├─LeakyReLU: 1-13                        [-1, 1024, 4, 4]          --\n",
      "├─Dropout2d: 1-14                        [-1, 1024, 4, 4]          --\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Conv2d: 2-24                      [-1, 512, 1, 1]           8,389,120\n",
      "├─Dropout2d: 1-15                        [-1, 512, 1, 1]           --\n",
      "├─Linear: 1-16                           [-1, 256]                 131,328\n",
      "├─Linear: 1-17                           [-1, 1]                   577\n",
      "==========================================================================================\n",
      "Total params: 12,751,809\n",
      "Trainable params: 12,751,809\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.60\n",
      "==========================================================================================\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 60.26\n",
      "Params size (MB): 48.64\n",
      "Estimated Total Size (MB): 109.09\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 64, 64]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 32, 128, 128]        4,704\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 32, 128, 128]        64\n",
       "|    └─LeakyReLU: 2-3                    [-1, 32, 128, 128]        --\n",
       "|    └─Conv2d: 2-4                       [-1, 64, 64, 64]          131,072\n",
       "|    └─BatchNorm2d: 2-5                  [-1, 64, 64, 64]          128\n",
       "|    └─LeakyReLU: 2-6                    [-1, 64, 64, 64]          --\n",
       "├─Dropout2d: 1-2                         [-1, 64, 64, 64]          --\n",
       "├─Sequential: 1-3                        [-1, 128, 64, 64]         --\n",
       "|    └─Conv2d: 2-7                       [-1, 128, 64, 64]         8,192\n",
       "|    └─BatchNorm2d: 2-8                  [-1, 128, 64, 64]         256\n",
       "├─Sequential: 1-4                        [-1, 128, 64, 64]         --\n",
       "|    └─Conv2d: 2-9                       [-1, 32, 64, 64]          2,048\n",
       "|    └─BatchNorm2d: 2-10                 [-1, 32, 64, 64]          64\n",
       "|    └─LeakyReLU: 2-11                   [-1, 32, 64, 64]          --\n",
       "|    └─Conv2d: 2-12                      [-1, 32, 64, 64]          9,248\n",
       "|    └─BatchNorm2d: 2-13                 [-1, 32, 64, 64]          64\n",
       "|    └─LeakyReLU: 2-14                   [-1, 32, 64, 64]          --\n",
       "|    └─Conv2d: 2-15                      [-1, 128, 64, 64]         4,096\n",
       "|    └─BatchNorm2d: 2-16                 [-1, 128, 64, 64]         256\n",
       "├─LeakyReLU: 1-5                         [-1, 128, 64, 64]         --\n",
       "├─Dropout2d: 1-6                         [-1, 128, 64, 64]         --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Sequential: 2-17                  [-1, 256, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 256, 32, 32]         32,768\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 256, 32, 32]         512\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Sequential: 2-18                  [-1, 256, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-3                  [-1, 64, 64, 64]          8,192\n",
       "|    |    └─BatchNorm2d: 3-4             [-1, 64, 64, 64]          128\n",
       "|    |    └─LeakyReLU: 3-5               [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-6                  [-1, 64, 64, 64]          36,928\n",
       "|    |    └─BatchNorm2d: 3-7             [-1, 64, 64, 64]          128\n",
       "|    |    └─LeakyReLU: 3-8               [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-9                  [-1, 256, 32, 32]         65,536\n",
       "|    |    └─BatchNorm2d: 3-10            [-1, 256, 32, 32]         512\n",
       "├─LeakyReLU: 1-7                         [-1, 256, 32, 32]         --\n",
       "├─Dropout2d: 1-8                         [-1, 256, 32, 32]         --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Sequential: 2-19                  [-1, 512, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-11                 [-1, 512, 16, 16]         131,072\n",
       "|    |    └─BatchNorm2d: 3-12            [-1, 512, 16, 16]         1,024\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Sequential: 2-20                  [-1, 512, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-13                 [-1, 128, 32, 32]         32,768\n",
       "|    |    └─BatchNorm2d: 3-14            [-1, 128, 32, 32]         256\n",
       "|    |    └─LeakyReLU: 3-15              [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-16                 [-1, 128, 32, 32]         147,584\n",
       "|    |    └─BatchNorm2d: 3-17            [-1, 128, 32, 32]         256\n",
       "|    |    └─LeakyReLU: 3-18              [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-19                 [-1, 512, 16, 16]         262,144\n",
       "|    |    └─BatchNorm2d: 3-20            [-1, 512, 16, 16]         1,024\n",
       "├─LeakyReLU: 1-9                         [-1, 512, 16, 16]         --\n",
       "├─Dropout2d: 1-10                        [-1, 512, 16, 16]         --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Sequential: 2-21                  [-1, 1024, 8, 8]          --\n",
       "|    |    └─Conv2d: 3-21                 [-1, 1024, 8, 8]          524,288\n",
       "|    |    └─BatchNorm2d: 3-22            [-1, 1024, 8, 8]          2,048\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Sequential: 2-22                  [-1, 1024, 8, 8]          --\n",
       "|    |    └─Conv2d: 3-23                 [-1, 256, 16, 16]         131,072\n",
       "|    |    └─BatchNorm2d: 3-24            [-1, 256, 16, 16]         512\n",
       "|    |    └─LeakyReLU: 3-25              [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-26                 [-1, 256, 16, 16]         590,080\n",
       "|    |    └─BatchNorm2d: 3-27            [-1, 256, 16, 16]         512\n",
       "|    |    └─LeakyReLU: 3-28              [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-29                 [-1, 1024, 8, 8]          1,048,576\n",
       "|    |    └─BatchNorm2d: 3-30            [-1, 1024, 8, 8]          2,048\n",
       "├─LeakyReLU: 1-11                        [-1, 1024, 8, 8]          --\n",
       "├─Dropout2d: 1-12                        [-1, 1024, 8, 8]          --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Sequential: 2-23                  [-1, 1024, 4, 4]          --\n",
       "|    |    └─Conv2d: 3-31                 [-1, 1024, 4, 4]          1,048,576\n",
       "|    |    └─BatchNorm2d: 3-32            [-1, 1024, 4, 4]          2,048\n",
       "├─LeakyReLU: 1-13                        [-1, 1024, 4, 4]          --\n",
       "├─Dropout2d: 1-14                        [-1, 1024, 4, 4]          --\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Conv2d: 2-24                      [-1, 512, 1, 1]           8,389,120\n",
       "├─Dropout2d: 1-15                        [-1, 512, 1, 1]           --\n",
       "├─Linear: 1-16                           [-1, 256]                 131,328\n",
       "├─Linear: 1-17                           [-1, 1]                   577\n",
       "==========================================================================================\n",
       "Total params: 12,751,809\n",
       "Trainable params: 12,751,809\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.60\n",
       "==========================================================================================\n",
       "Input size (MB): 0.19\n",
       "Forward/backward pass size (MB): 60.26\n",
       "Params size (MB): 48.64\n",
       "Estimated Total Size (MB): 109.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = resDiscriminator(reduction=4,repeat=0,n_map=32,reduction_p2=1)\n",
    "summary(discriminator,torch.zeros(1,3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resGenerator(nn.Module):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
